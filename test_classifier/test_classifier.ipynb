{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from cloudpickle import load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import TableArtifact, PlotArtifact\n",
    "\n",
    "from mlrun.mlutils import plot_roc, plot_importance, gcf_clear\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "def _gcf_clear(plt):\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()        \n",
    "\n",
    "def test_classifier(\n",
    "    context: MLClientCtx,\n",
    "    models_path: str, \n",
    "    test_set: str,\n",
    "    label_column: str,\n",
    "    score_method: str = 'micro',\n",
    "    plots_dest: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"Test one or more classifier models against held-out dataset\n",
    "    \n",
    "    Using held-out test features, evaluates the peformance of the estimated model\n",
    "    \n",
    "    Can be part of a kubeflow pipeline as a test step that is run post EDA and \n",
    "    training/validation cycles\n",
    "    \n",
    "    :param context:         the function context\n",
    "    :param models_path:     artifact models representing a file or a folder\n",
    "    :param test_set:        test features and labels\n",
    "    :param label_column:    column name for ground truth labels\n",
    "    :param score_method:    for multiclass classification\n",
    "    :param plots_dest:       dir for test plots\n",
    "    \"\"\"\n",
    "    xtest = pd.read_parquet(str(test_set))\n",
    "    ytest = xtest.pop(label_column)\n",
    "    \n",
    "    context.header = list(xtest.columns.values)\n",
    "    def _eval_model(model):\n",
    "        # enclose all except model\n",
    "        ytestb = label_binarize(ytest, classes=ytest.unique())\n",
    "        clf = load(open(model, \"rb\"))\n",
    "        if callable(getattr(clf, \"predict_proba\")):\n",
    "            y_score = clf.predict_proba(xtest.values)\n",
    "            ypred = clf.predict(xtest.values)\n",
    "            context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "            context.logger.info(f\"ytestb.shape {ytestb.shape}\")\n",
    "            plot_roc(context, ytestb, y_score, key='roc', plots_dir=plots_dest)\n",
    "        else:\n",
    "            ypred = clf.predict(xtest.values) # refactor\n",
    "            y_score = None\n",
    "            \n",
    "        gcf_clear(plt)\n",
    "        # use sklearn >= v0.22 built in:\n",
    "       \n",
    "        metrics.plot_confusion_matrix(clf, xtest, ytest, \n",
    "                                      labels=ytest.unique(), normalize='true') \n",
    "        \n",
    "        context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf()), \n",
    "                             local_path=f\"{plots_dest}/confusion.html\")        \n",
    "    \n",
    "        #if hasattr(clf, \"feature_importances_\"):\n",
    "        #    plot_importance(context, clf, key=f\"featimp\")\n",
    "\n",
    "        ytestb = label_binarize(ytest, classes=ytest.unique()) # if binary 0/1 labels, will return labels as is\n",
    "        context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "        context.logger.info(f\"yvalidb.shape {ytestb.shape}\")\n",
    "        if ytestb.shape[1] > 1:\n",
    "            # label encoding was applied:\n",
    "            average_precision = metrics.average_precision_score(ytestb,\n",
    "                                                                y_score,\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(ytestb, y_score))\n",
    "        else:\n",
    "            average_precision = metrics.average_precision_score(ytestb,\n",
    "                                                                y_score[:, 1],\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(ytestb, y_score[:, 1]))\n",
    "\n",
    "        context.log_result(f\"avg_precscore\", average_precision)\n",
    "        context.log_result(f\"accuracy\", float(clf.score(xtest, ytest)))\n",
    "        context.log_result(f\"f1_score\", metrics.f1_score(ytest, ypred,\n",
    "                                                         average=score_method))\n",
    "    \n",
    "    models_path = str(models_path)\n",
    "    if models_path.endswith('.pkl'):\n",
    "        _eval_model(models_path)\n",
    "        \n",
    "    else:\n",
    "        for model in os.listdir(models_path):\n",
    "            if model.endswith('.pkl'):\n",
    "                _eval_model(os.path.join(models_path, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-29 21:05:30,961 saving function: test-classifier, tag: latest\n",
      "[mlrun] 2020-03-29 21:05:30,992 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fa64db53160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"test_classifier\", kind=\"job\", with_doc=True,\n",
    "                      image=\"mlrun/ml-models\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"test_classifier\"\n",
    "fn.spec.description = \"test a classifier using held-out or new data\"\n",
    "fn.metadata.categories = [\"models\", \"testing\"]\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-26 15:30:16,927 starting run tasks - test classifier uid=7cfeb84664524a3a8713d62b10dd66ef  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-03-26 15:30:17,027 Job is running in the background, pod: tasks---test-classifier-pdzhs\n",
      "No handles with labels found to put in legend.\n",
      "[mlrun] 2020-03-26 15:30:27,471 y_score.shape (57, 2)\n",
      "[mlrun] 2020-03-26 15:30:27,471 ytestb.shape (57, 1)\n",
      "[mlrun] 2020-03-26 15:30:27,583 log artifact roc at /User/artifacts/plots/roc.html, size: 31054, db: Y\n",
      "[mlrun] 2020-03-26 15:30:27,697 log artifact confusion at /User/artifacts/plots/confusion.html, size: 20680, db: Y\n",
      "[mlrun] 2020-03-26 15:30:27,698 y_score.shape (57, 2)\n",
      "[mlrun] 2020-03-26 15:30:27,698 yvalidb.shape (57, 1)\n",
      "[mlrun] 2020-03-26 15:30:27,713 log artifact TODAYS-MODELS-TEST-REPORT at /User/artifacts/model.pkl, size: None, db: Y\n",
      "[mlrun] 2020-03-26 15:30:27,724 log artifact DEPLOY at /User/artifacts/DEPLOY, size: 4, db: Y\n",
      "\n",
      "[mlrun] 2020-03-26 15:30:27,737 run executed, status=completed\n",
      "final state: succeeded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"7cfeb84664524a3a8713d62b10dd66ef\">...dd66ef</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Mar 26 15:30:27</td>\n",
       "      <td>completed</td>\n",
       "      <td>tasks - test classifier</td>\n",
       "      <td><div class=\"dictlist\">host=tasks---test-classifier-pdzhs</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">models_dir=/User/artifacts/models</div><div class=\"dictlist\">test_set=/User/artifacts/test_set.parquet</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.9298245614035088</div><div class=\"dictlist\">avg_precscore=0.9920335330006206</div><div class=\"dictlist\">f1_score=0.9298245614035088</div><div class=\"dictlist\">rocauc=0.9900744416873448</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulte41afa81\" title=\"/files/artifacts/plots/roc.html\">roc</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulte41afa81\" title=\"/files/artifacts/plots/confusion.html\">confusion</div><div title=\"/User/artifacts/model.pkl\">TODAYS-MODELS-TEST-REPORT</div><div title=\"/User/artifacts/DEPLOY\">DEPLOY</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resulte41afa81-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resulte41afa81-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resulte41afa81\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resulte41afa81-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 7cfeb84664524a3a8713d62b10dd66ef  , !mlrun logs 7cfeb84664524a3a8713d62b10dd66ef \n",
      "[mlrun] 2020-03-26 15:30:36,259 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "from mlrun import import_function, mount_v3io\n",
    "\n",
    "func = import_function(\"hub://test_classifier\").apply(mount_v3io())\n",
    "# func = import_function(\"function.yaml\").apply(mlrun.mount_v3io())\n",
    "\n",
    "task_params = {\n",
    "    \"name\" : \"tasks - test classifier\",\n",
    "    \"params\": {\n",
    "        # Ina pipeline setting, the models_path parameter would be the output of a training step\n",
    "        \"models_path\"   : \"/User/artifacts/models\",\n",
    "        \"test_set\"      : \"/User/artifacts/test_set.parquet\",\n",
    "        \"label_column\"  : \"labels\"}}\n",
    "\n",
    "from mlrun import NewTask\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
