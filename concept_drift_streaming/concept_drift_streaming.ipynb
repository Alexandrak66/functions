{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "python -m pip install scikit-multiflow==0.4.1\n",
    "python -m pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio'\n",
      "%nuclio: setting spec.build.baseImage to 'mlrun/ml-models:0.4.7'\n"
     ]
    }
   ],
   "source": [
    "# Define function spec\n",
    "%nuclio config kind = \"nuclio\"\n",
    "%nuclio config spec.build.baseImage = \"mlrun/ml-models:0.4.7\"\n",
    "\n",
    "# Add V3IO Mount\n",
    "# %nuclio env %v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "env = {'label_col': 'resp',\n",
    "       'prediction_col': 'prediction',\n",
    "       'drift_stream': '/bigdata/network-operations/drift_stream',\n",
    "       'tsdb_table': 'network-operations/drift_tsdb',\n",
    "       'pagehinkley_threshold': 10,\n",
    "       'models': ['pagehinkley', 'ddm', 'eddm'],\n",
    "       'window_size': 10}\n",
    "config = {'kind': 'nuclio',\n",
    "          'spec.build.baseImage': 'mlrun/ml-models:0.4.7'}\n",
    "cmd = ['python -m pip install scikit-multiflow',\n",
    "       'python -m pip install v3io_frames']\n",
    "v3io = True\n",
    "config = nuclio.ConfigSpec(env=env,\n",
    "                           config=config,\n",
    "                           cmd=cmd,\n",
    "                           v3io=v3io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'label_col' environment variable\n",
      "%nuclio: setting 'prediction_col' environment variable\n",
      "%nuclio: setting 'drift_stream' environment variable\n",
      "%nuclio: setting 'tsdb_table' environment variable\n",
      "%nuclio: setting 'pagehinkley_threshold' environment variable\n",
      "%nuclio: setting 'models' environment variable\n",
      "%nuclio: setting 'window_size' environment variable\n"
     ]
    }
   ],
   "source": [
    "# # Streams\n",
    "# %nuclio env label_col = resp\n",
    "# %nuclio env prediction_col = prediction\n",
    "# %nuclio env drift_stream = /bigdata/network-operations/drift_stream\n",
    "# %nuclio env tsdb_table = network-operations/drift_tsdb\n",
    "\n",
    "# # Algorithms\n",
    "# %nuclio env pagehinkley_threshold = 10\n",
    "# %nuclio env pagehinkely_model_path = /User/artifacts/ph.pkl\n",
    "# %nuclio env ddm_model_path = /User/artifacts/ddm.pkl\n",
    "# %nuclio env eddm_model_path = /User/artifacts/eddm.pkl\n",
    "\n",
    "# # Configurations\n",
    "# # %nuclio env callbacks = \n",
    "# %nuclio env window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultiflow.drift_detection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import v3io.dataplane\n",
    "import v3io_frames as v3f\n",
    "import requests\n",
    "from cloudpickle import load\n",
    "\n",
    "# For testing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path(mntpath=''):\n",
    "    if mntpath[0] == '/':\n",
    "        mntpath = mntpath[1:]\n",
    "    paths = mntpath.split('/')\n",
    "    container = paths[0]\n",
    "    subpath = ''\n",
    "    if len(paths) > 1:\n",
    "        subpath = mntpath[len(container):]\n",
    "    return container, subpath\n",
    "\n",
    "\n",
    "def create_stream(context, path, shards=1):\n",
    "    # create a stream w/8 shards\n",
    "    container, stream_path = split_path(path)\n",
    "    context.logger.info(f'Creating stream in Container: {container} & Path {stream_path}')\n",
    "    response = context.v3io_client.create_stream(container=container,\n",
    "                                        path=stream_path, \n",
    "                                        shard_count=shards,\n",
    "                                        raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    response.raise_for_status([409, 204])\n",
    "    \n",
    "    \n",
    "def push_to_stream(context, stream_path, data):\n",
    "    records = [{'data': json.dumps(rec)} for rec in data]\n",
    "    container, stream_path = split_path(stream_path)\n",
    "    response = context.v3io_client.put_records(container=container,\n",
    "                                               path=stream_path, \n",
    "                                               records=records)\n",
    "\n",
    "\n",
    "def construct_record(record):\n",
    "    label_col = os.getenv('label_col', 'label')\n",
    "    prediction_col = os.getenv('prediction_col', 'prediction')\n",
    "    res = dict([(k, record[k]) for k in ['when', 'class', 'model', 'resp', 'request']])\n",
    "    res['feature_vector'] = res.pop('request')['instances'][0]\n",
    "    res['timestamp'] = res.pop('when')\n",
    "    res['prediction'] = res['resp'][0]\n",
    "    \n",
    "    ## For Testing - Start\n",
    "    label_chance = random.random()\n",
    "    if res['prediction'] == 0:\n",
    "        res['label'] = 0 if label_chance > 0.3 else 1\n",
    "    else:\n",
    "        res['label'] = 1 if label_chance > 0.8 else 0\n",
    "    ## For Testing - End\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    # create a v3io context object\n",
    "    v3io_client = v3io.dataplane.Client()\n",
    "    setattr(context, \"v3io_client\", v3io_client)\n",
    "    \n",
    "    # Setup windowing for TSDB writer\n",
    "    v3f_client = v3f.Client('framesd:8081', container='bigdata')\n",
    "    setattr(context, \"v3f\", v3f_client)\n",
    "    window = []\n",
    "    setattr(context, 'window', window)\n",
    "    setattr(context, 'window_size', int(os.getenv('window_size', 10)))\n",
    "    setattr(context, 'tsdb_table', os.getenv('tsdb_table', 'concept_drift_tsdb_1'))\n",
    "    try:\n",
    "        context.v3f.create('tsdb', context.tsdb_table, rate='1/s', if_exists=1)\n",
    "    except Exception as e:\n",
    "        context.logger.info(f'Creating context with rate= faile for {e}')\n",
    "        context.v3f.create('tsdb', context.tsdb_table, attrs={'rate': '1/s'}, if_exists=1)\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [callback.strip() for callback in os.getenv('callbacks', '').split(',')]\n",
    "    setattr(context, 'callbacks', callbacks)\n",
    "    \n",
    "    # Setup drift stream\n",
    "    setattr(context, 'drift_stream', os.getenv('drift_stream', '/bigdata/drift_stream'))\n",
    "    try:\n",
    "        create_stream(context, context.drift_stream, int(os.getenv('drift_stream_shards', 1)))\n",
    "    except:\n",
    "        context.logger.info(f'{context.drift_stream} already exists')\n",
    "    \n",
    "    # Load models\n",
    "    models = {}\n",
    "    model_types = ['pagehinkely', 'ddm', 'eddm']\n",
    "    path_suffix = '_model_path'\n",
    "    for model in model_types:\n",
    "        model_env = f'{model}{path_suffix}'\n",
    "        if model_env in os.environ:\n",
    "            with open(os.environ[model_env], 'rb') as f:\n",
    "                models[model] = load(f)\n",
    "    setattr(context, 'models', models)\n",
    "    \n",
    "    # Columns to check\n",
    "    setattr(context, 'label_col', os.getenv('label_col', 'label'))\n",
    "    setattr(context, 'prediction_col', os.getenv('prediction_col', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    # Construct event\n",
    "    context.logger.info(f'event: {event.body}')\n",
    "    full_event = json.loads(event.body)\n",
    "    record = construct_record(full_event)\n",
    "    \n",
    "    # Is our prediction wrong?\n",
    "    is_error = record[context.label_col] != record[context.prediction_col]\n",
    "    context.logger.info(f'Adding {is_error}')\n",
    "    \n",
    "    # Process the {is_error} element with our algorithms\n",
    "    for name, model in context.models.items():\n",
    "        # Add element\n",
    "        results = {'timestamp': record['timestamp']}\n",
    "        results['algorithm'] = name\n",
    "        model.add_element(is_error)\n",
    "        \n",
    "        # Detect warning zone (if applicable to the algorithm)\n",
    "        if hasattr(model, 'detected_warning_zone') and model.detected_warning_zone():\n",
    "            context.logger.info(f'{name}\\tWarning zone detected')\n",
    "            results['warning_zone'] = 1\n",
    "            full_event[f'{name}_warning_zone'] = 1\n",
    "        else:\n",
    "            results['warning_zone'] = 0\n",
    "            full_event[f'{name}_warning_zone'] = 0\n",
    "        \n",
    "        # Detect drift\n",
    "        if model.detected_change():\n",
    "            context.logger.info('Change Detected')\n",
    "            results['change_detected'] = 1\n",
    "            full_event[f'{name}_drift'] = 1\n",
    "        else:\n",
    "            results['change_detected'] = 0\n",
    "            full_event[f'{name}_drift'] = 0\n",
    "        context.window.append(results)\n",
    "    \n",
    "    # Return results\n",
    "    # Write to stream\n",
    "    push_to_stream(context, context.drift_stream, [full_event])\n",
    "    \n",
    "    # Add to callbacks\n",
    "    if context.callbacks != ['']:\n",
    "        for callback in context.callbacks:\n",
    "            requests.post(url=callback,\n",
    "                          json=full_event)\n",
    "    \n",
    "    if (len(context.window) / len(context.models)) >= context.window_size:\n",
    "        df = pd.DataFrame(context.window)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.set_index(['timestamp', 'algorithm'])\n",
    "        context.v3f.write('tsdb', context.tsdb_table, df)\n",
    "        context.window = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_context(context)\n",
    "event = nuclio.Event(body=json.dumps({'prediction': 0,\n",
    "                                      'when': 'now',\n",
    "                                      'class': 'ClassModel', \n",
    "                                      'model': 'tester_v1', \n",
    "                                      'resp': [0], \n",
    "                                      'request': {'instances': [[1, 1.2, 3]]}}))\n",
    "out = handler(context, event)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio deploy -n network-operations-concept-drift -p network-operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save function yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from mlrun import run_local, NewTask, mlconf, import_function, mount_v3io, code_to_function, get_run_db\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-06-02 11:55:25,750 function spec saved to path: /User/functions/concept_drift_streaming/function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fc5fd2339b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"concept_drift_streaming\", kind='nuclio')\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"handler\"\n",
    "fn.spec.description = \"Deploy a streaming Concept Drift detector on a labeled stream\"\n",
    "fn.metadata.categories = [\"ml\", \"serve\"]\n",
    "fn.metadata.labels = {\"author\": \"orz\", \"framework\": \"sklearn\"}\n",
    "fn.export(\"/User/functions/concept_drift_streaming/function.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_trigger = nuclio.triggers.V3IOStreamTrigger(url='/bigdata/network-operations/inference_stream@cd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fa1dc063780>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.add_trigger('labeled_stream', stream_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fa1dc063780>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.apply(mount_v3io()).with_v3io()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = import_function('./function.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.deploy(project='network-operations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3io_client = v3io.dataplane.Client()\n",
    "def sum_stream(path, shard='0', seek_type='EARLIEST'):\n",
    "    # seek the shard to the first record in it\n",
    "    container, stream_path = split_path(path)\n",
    "    shard_path = os.path.join(stream_path, shard)\n",
    "    response = v3io_client.seek_shard(container=container,\n",
    "                                      path=shard_path, \n",
    "                                      seek_type=seek_type)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # get records, starting from the location we got from seek\n",
    "    response = v3io_client.get_records(container=container,\n",
    "                                       path=shard_path, \n",
    "                                       location=response.output.location)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    models = ['pagehinkley', 'eddm', 'ddm']\n",
    "    result_record = response.output.records\n",
    "    results = {}\n",
    "    for model in models:\n",
    "        results[f'{model}_change_detected'] = sum([json.loads(record.data)[f'{model}_drift'] for record in result_record])\n",
    "        results[f'{model}_warning'] = sum([json.loads(record.data)[f'{model}_warning_zone'] for record in result_record])\n",
    "    return results\n",
    "\n",
    "def print_stream(path, shard='0', seek_type='EARLIEST', last=10):\n",
    "    # seek the shard to the first record in it\n",
    "    container, stream_path = split_path(path)\n",
    "    shard_path = os.path.join(stream_path, shard)\n",
    "    response = v3io_client.seek_shard(container=container,\n",
    "                                      path=shard_path, \n",
    "                                      seek_type=seek_type)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # get records, starting from the location we got from seek\n",
    "    response = v3io_client.get_records(container=container,\n",
    "                                       path=shard_path, \n",
    "                                       location=response.output.location)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    models = ['pagehinkley', 'eddm', 'ddm']\n",
    "    result_record = response.output.records\n",
    "    print([json.loads(record.data) for record in result_record[:last]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'op': 'predict', 'class': 'ClassifierModel', 'worker': '0', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[80.1253411332047, 2.34553138118514, 0.17092217232779894, 248.64588869674128, 712.5415750520383, 220.34346499602648]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.338650', 'microsec': 3591}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '1', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[81.42838269615248, 0.49070601780755807, 0.0, 246.26702871478165, 770.9462773080015, 246.26702871478165]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.390042', 'microsec': 2040}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '2', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[81.53769726349861, 6.675420076909625, 0.0, 224.2162189810224, 748.7160085455595, 224.2162189810224]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.427830', 'microsec': 2519}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '3', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[53.028151817163675, 6.900792681653051, 0.7025685339203552, 249.88022141711843, 692.4745622533163, 205.59940508746178]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.470243', 'microsec': 3018}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '4', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[80.95429997027495, 1.3549399067725174, 1.0647593494178564, 262.19798706434995, 726.1666188930001, 211.06151811284016]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.509943', 'microsec': 2053}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '5', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[100.0, 100.0, 50.0, 273.42633152722374, 762.3656580712258, 225.34432692889115]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.543565', 'microsec': 2035}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '6', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[83.72469933635489, 1.2505972522702022, 0.0, 239.90178604373227, 750.0397813709451, 239.90178604373227]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.580922', 'microsec': 2106}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '7', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[64.03125025788283, 0.6326878428083632, 0.0, 251.6928744112008, 786.8907152248685, 251.6928744112008]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.617083', 'microsec': 2005}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '0', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[53.701562044196606, 7.611908131024853, 0.0, 203.81987668093882, 706.1262001449211, 203.81987668093882]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.651123', 'microsec': 1969}, {'op': 'predict', 'class': 'ClassifierModel', 'worker': '1', 'model': 'predictor', 'host': 'nuclio-network-operations-netops-server-v1-6f7b68bbd5-79sbx', 'request': {'instances': [[63.33420107442403, 0.21794571752982145, 0.0, 204.8167467045585, 711.5074726210469, 204.8167467045585]]}, 'resp': [False], 'when': '2020-05-20 17:35:56.686822', 'microsec': 1961}]\n"
     ]
    }
   ],
   "source": [
    "print_stream('/bigdata/network-operations/inference_stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test live endpoint with model_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = import_function('hub://model_server_tester').apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = code_to_function(filename='/User/functions/model_server_tester/model_server_tester.ipynb', kind='local', code_output='./tester.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>packet_loss</th>\n",
       "      <th>throughput</th>\n",
       "      <th>is_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>company</th>\n",
       "      <th>data_center</th>\n",
       "      <th>device</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-03-29 19:22:10.106</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Johnson-Morgan</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Glenn_Port</th>\n",
       "      <th>6625659405376</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0306839395881</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Baker_Locks</th>\n",
       "      <th>9686333640344</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135824620701</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romero-Perry</th>\n",
       "      <th>Kim_Locks</th>\n",
       "      <th>9598503476170</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  packet_loss  \\\n",
       "timestamp               company        data_center device                       \n",
       "2020-03-29 19:22:10.106 Johnson-Morgan Glenn_Port  6625659405376           30   \n",
       "                                                   0306839395881           30   \n",
       "                                       Baker_Locks 9686333640344           30   \n",
       "                                                   6135824620701           30   \n",
       "                        Romero-Perry   Kim_Locks   9598503476170           30   \n",
       "\n",
       "                                                                  throughput  \\\n",
       "timestamp               company        data_center device                      \n",
       "2020-03-29 19:22:10.106 Johnson-Morgan Glenn_Port  6625659405376          50   \n",
       "                                                   0306839395881          50   \n",
       "                                       Baker_Locks 9686333640344          50   \n",
       "                                                   6135824620701          50   \n",
       "                        Romero-Perry   Kim_Locks   9598503476170          50   \n",
       "\n",
       "                                                                  is_error  \n",
       "timestamp               company        data_center device                   \n",
       "2020-03-29 19:22:10.106 Johnson-Morgan Glenn_Port  6625659405376     False  \n",
       "                                                   0306839395881     False  \n",
       "                                       Baker_Locks 9686333640344     False  \n",
       "                                                   6135824620701     False  \n",
       "                        Romero-Perry   Kim_Locks   9598503476170     False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "table = '/v3io/bigdata/concept_drift_ex/tests/feature_change.pq'\n",
    "df = pd.read_parquet(table)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_parquet('/User/v3io/bigdata/concept_drift_ex/selected_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['packet_loss'] = 30\n",
    "t['throughput'] = 50\n",
    "t.to_parquet('/v3io/bigdata/concept_drift_ex/tests/feature_change.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function locally\n",
    "addr = 'http://192.168.224.209:32418'\n",
    "\n",
    "table = '/User/v3io/bigdata/concept_drift_ex/selected_features.parquet' # Base dataset\n",
    "# table = '/User/v3io/bigdata/concept_drift_ex/tests/test_set_true.pq' # All labels = True\n",
    "# table = '/User/v3io/bigdata/concept_drift_ex/tests/test_set_false.pq' # All labels = False\n",
    "# table = '/v3io/bigdata/concept_drift_ex/tests/feature_change.pq' # Feature change\n",
    "for i in range(10):\n",
    "    cmd.run(name='model_server_tester', \n",
    "            handler='model_server_tester',\n",
    "            params={'addr': addr, \n",
    "                    'model': 'predictor', \n",
    "                    'label_column':'is_error'},\n",
    "            inputs={'table': table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
